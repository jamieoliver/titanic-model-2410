{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f705fb-dd83-4242-afd5-f791fe198e1c",
   "metadata": {},
   "source": [
    "# Titanic: Survival Model\n",
    "\n",
    "Build and train a model to predict survival on the Titanic using a [cleaned and split dataset](https://huggingface.co/datasets/jamieoliver/titanic-2410), and upload the model to Hugging Face.\n",
    "\n",
    "Based on https://github.com/fastai/course22/blob/master/clean/05-linear-model-and-neural-net-from-scratch.ipynb using the dataset from https://www.kaggle.com/competitions/titanic.\n",
    "\n",
    "Plan\n",
    "- [x] Download [cleaned and split dataset](https://huggingface.co/datasets/jamieoliver/titanic-2410) from Hugging Face\n",
    "- [x] Prepare data for model\n",
    "    - [x] Load training dataset as PyTorch tensors\n",
    "    - [x] Normalise training dataset\n",
    "- [ ] Train model\n",
    "- [ ] Test model\n",
    "- [ ] Upload model to Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bd16e-9fbd-4d9d-a400-fabc8ff7f2e6",
   "metadata": {},
   "source": [
    "##  Download Dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928b3381-2e66-47ea-b937-b848141f0cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "        num_rows: 712\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "        num_rows: 179\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "        num_rows: 418\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import *\n",
    "\n",
    "datasetDict = load_dataset('jamieoliver/titanic-2410')\n",
    "datasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50258aa3-5330-4970-a655-2e9eacd3c502",
   "metadata": {},
   "source": [
    "## Prepare Data for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c91b29-6e0c-4952-ab70-59eb24254d5e",
   "metadata": {},
   "source": [
    "### Load Training Dataset as PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d762c5e-33d5-4f62-a8a8-5b6327c26e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import *\n",
    "from torch.utils.data import *\n",
    "\n",
    "set_printoptions(linewidth=120, edgeitems=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366f362e-4d3a-4bd6-ac99-67a9ca403d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "    num_rows: 712\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasetDict['train']\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93576a-78cf-4ce4-840b-c967435777e7",
   "metadata": {},
   "source": [
    "The dependent variable is the variable we are predicting i.e. `survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8bd00a-69b5-4923-bb8e-39612871d383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_var = tensor(train_dataset.to_pandas()['Survived'].values, dtype=float)\n",
    "dependent_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef193d95-c2f7-47cb-9798-7c4a49a1fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([712])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faac882-da41-45a9-a4b2-9cc35fbcfb9a",
   "metadata": {},
   "source": [
    "The independent variables are the variables we will use to make the prediction. Note that we use a trick in mutiplying the Pandas DataFrame by 1 to convert booleans to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bdd66b-2dd7-4d0e-9434-d4b185d39558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  0.0000,  0.0000,  2.0949,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  2.0000,  0.0000,  4.3108,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  5.4316,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [32.0000,  0.0000,  0.0000,  4.3476,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [30.0000,  0.0000,  0.0000,  2.1102,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [18.0000,  0.0000,  2.0000,  2.6391,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [47.0000,  1.0000,  1.0000,  3.9807,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [34.0000,  0.0000,  0.0000,  2.4423,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [39.0000,  1.0000,  1.0000,  4.7175,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [50.0000,  0.0000,  1.0000,  5.5155,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [20.0000,  1.0000,  0.0000,  2.3819,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [31.0000,  0.0000,  0.0000,  2.1691,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [24.0000,  2.0000,  3.0000,  2.9832,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [21.0000,  0.0000,  0.0000,  2.1102,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [50.0000,  0.0000,  0.0000,  2.4423,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [22.0000,  0.0000,  0.0000,  2.1691,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [45.0000,  0.0000,  0.0000,  2.6741,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [33.0000,  1.0000,  1.0000,  3.0692,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [40.0000,  0.0000,  0.0000,  5.0400,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  2.1459,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_cols = ['Age', 'SibSp', 'Parch', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "                    'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "independent_vars = tensor((train_dataset.to_pandas()*1)[independent_cols].values, dtype=float)\n",
    "independent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b4dfcd-b5b4-4ea6-8a80-d581396f41b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([712, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_vars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3fcf76-c29a-4cd5-8d01-84c4e5196247",
   "metadata": {},
   "source": [
    "### Normalise Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba95ae83-5b4a-4198-a8f6-d527714d8c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2973, 0.0000, 0.0000, 0.3357, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3243, 0.2500, 0.0000, 0.6907, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3243, 0.0000, 0.0000, 0.8703, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.4324, 0.0000, 0.0000, 0.6966, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.4054, 0.0000, 0.0000, 0.3381, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.2432, 0.0000, 0.3333, 0.4229, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.6351, 0.1250, 0.1667, 0.6378, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4595, 0.0000, 0.0000, 0.3913, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.5270, 0.1250, 0.1667, 0.7559, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.6757, 0.0000, 0.1667, 0.8838, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.2703, 0.1250, 0.0000, 0.3817, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4189, 0.0000, 0.0000, 0.3476, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.3243, 0.2500, 0.5000, 0.4780, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.2838, 0.0000, 0.0000, 0.3381, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.6757, 0.0000, 0.0000, 0.3913, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.2973, 0.0000, 0.0000, 0.3476, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.6081, 0.0000, 0.0000, 0.4285, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4459, 0.1250, 0.1667, 0.4918, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.5405, 0.0000, 0.0000, 0.8076, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3243, 0.0000, 0.0000, 0.3438, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals,indices = independent_vars.max(dim=0)\n",
    "independent_vars /= max_vals\n",
    "independent_vars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
